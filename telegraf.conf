# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "1s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false


[[inputs.kafka_consumer]]
  ## Kafka brokers.
  brokers = ["$KAFKA_BROKER"]

  ## Topics to consume.
  topics = ["$KAFKA_TOPIC"]

  ## Name of the consumer group.
  consumer_group = "$KAFKA_CONSUMER_GROUP"

  ## Initial offset position; one of "oldest" or "newest".
  offset = "newest"

  ## Maximum length of a message to consume, in bytes (default 0/unlimited);
  ## larger messages are dropped
  max_message_len = 1000000

  ## Drop all system measurements"
  namedrop = ["cpu", "disk", "diskio", "kernel", "mem", "processes", "swap", "system"]

  ## Data format to consume.
  data_format = "influx"
  influx_parser_type = "upstream"


[[outputs.influxdb_v2]]
  ## The URLs of the InfluxDB cluster nodes.
  urls = ["$INFLUXDB_URL"]

  ## Token for authentication.
  token = "$INFLUXDB_TOKEN"

  ## Organization is the name of the organization you wish to write to.
  organization = "$ORGANIZATION"

  ## Destination bucket to write into.
  bucket = "$BUCKET"

  ## Content-Encoding for write request body, can be set to "gzip" to
  content_encoding = "gzip"
